# ğŸ”­ Automatic Lens Distortion Correction â€” A100-Optimised CNN

> A high-performance deep learning pipeline that automatically corrects lens distortion in real estate and property photography using **EfficientNetB3** and differentiable **Brown-Conrady** undistortion, optimised for NVIDIA A100 GPUs on Google Colab Pro.

ğŸ““ **[Open in Google Colab](https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E?usp=sharing)**

---

## ğŸ“¸ Sample Dataset Images

These are real property photographs from the test dataset. Each image exhibits typical wide-angle lens distortion â€” bowed walls, curved ceilings, warped floor lines â€” that the model learns to detect and correct.

**Property 1 â€” 13 Caledonian St, Aberdare**

| Bathroom | Living / Dining |
|:---:|:---:|
| ![Bathroom with barrel distortion on tiles](assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g7.jpg) | ![Living/dining with curved ceiling lines](assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g2.jpg) |
| *Barrel distortion visible on tile grid lines* | *Wide-angle warp on ceiling and floor* |

**Property 2 â€” 105 Boulder Ridge Trail**

| Master Bedroom | Ensuite Bathroom | Hallway |
|:---:|:---:|:---:|
| ![Master bedroom wide-angle warp](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g8.jpg) | ![Ensuite with marble tile distortion](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g4.jpg) | ![Hallway perspective distortion](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g18.jpg) |
| *Bowed carpet and wall geometry* | *Marble tile grid warping* | *Converging wall lines* |

| Open Plan Living | Walk-in Closet |
|:---:|:---:|
| ![Open plan living floor bow](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g19.jpg) | ![Walk-in closet shelving distortion](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g7.jpg) |
| *Bowed hardwood floor lines* | *Warped shelf geometry* |

**Property 3 â€” Spiro Collection**

| Bathroom Vanity | Dining Room | Walk-in Closet | Bedroom Closet |
|:---:|:---:|:---:|:---:|
| ![Bathroom vanity curved counter](assets/spiro-c7bc93c5-bdd6-4bfc-19eb-08de68980cd7_g13.jpg) | ![Dining room wall panel warp](assets/spiro-aecdfdbb-7e25-4407-178c-08de6897d3cf_g4.jpg) | ![Walk-in closet shelving](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g7.jpg) | ![Bedroom closet door frame](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g3.jpg) |
| *Curved granite counter top* | *Wall panel vertical lines bowed* | *Shelving unit warp* | *Door frame barrel effect* |

---

## ğŸ¯ Overview

Lens distortion is a systematic optical imperfection where straight lines in the real world appear curved in photographs â€” very common in real estate photography where wide-angle lenses are used to make rooms look larger.

This pipeline works in two stages:

- **Stage 1 â€” Detection:** **EfficientNetB3** examines the distorted photo and predicts 4 distortion coefficients `[kâ‚, kâ‚‚, pâ‚, pâ‚‚]` that describe the lens geometry
- **Stage 2 â€” Correction:** The **Brown-Conrady mathematical model** uses those 4 numbers to compute exactly where every pixel should be, then remaps it using differentiable bilinear sampling

The CNN never directly manipulates pixels â€” it only predicts 4 numbers. All pixel manipulation is deterministic mathematics, which means the correction is geometrically principled and resolution-independent.

---

## âœ¨ Key Features

- **EfficientNetB3 Backbone** â€” 12M parameter pretrained ImageNet model, native 300Ã—300 input, detects subtle geometric distortion patterns
- **bfloat16 Mixed Precision** â€” 3Ã— throughput vs float32 on A100, no loss scaling needed
- **XLA JIT Compilation** â€” 20â€“40% additional speedup via GPU kernel fusion
- **Differentiable Geometry** â€” Brown-Conrady undistortion with backprop-safe bilinear sampling
- **Two-Phase Transfer Learning** â€” frozen backbone â†’ progressive fine-tuning of top 80 layers
- **Three-Component Loss** â€” SSIM + Sobel Edge + L1 prevents degenerate zero-coefficient solutions
- **Memory-Safe Pipeline** â€” ~1.3 GB peak RAM via `tf.data` + local SSD streaming
- **Parallel I/O** â€” `gsutil -m cp` bulk download + native TF decode (15â€“20Ã— faster than Python GCS clients)

---

## ğŸ—ï¸ Architecture

```
Distorted Image (384Ã—384)
        â†“
[CNN Encoder â€” EfficientNetB3]
  â€¢ Pretrained ImageNet weights (12M parameters)
  â€¢ Global Average Pooling â†’ (1536,)
        â†“
[Regression Head]
  â€¢ Dense(512, swish) + Dropout(0.3)
  â€¢ Dense(256, swish) + Dropout(0.2)
  â€¢ Dense(64,  swish)
  â€¢ Dense(4, tanh) + ScaleCoefficients layer
        â†“
  [kâ‚, kâ‚‚, pâ‚, pâ‚‚] â€” 4 distortion coefficients
        â†“
[Differentiable Brown-Conrady Undistortion]
  â€¢ build_distortion_grid()  â€” XLA compiled
  â€¢ bilinear_sample()        â€” differentiable pixel sampling
        â†“
Corrected Output Image (384Ã—384)
        â†“
Loss = 0.5 Ã— (1 âˆ’ SSIM) + 0.3 Ã— Sobel Edge + 0.2 Ã— L1
```

### What the 4 Coefficients Mean

| Coefficient | Range | Controls |
|---|---|---|
| `kâ‚` | `[âˆ’1.0, 1.0]` | Primary radial distortion â€” barrel (negative) or pincushion (positive) |
| `kâ‚‚` | `[âˆ’0.5, 0.5]` | Secondary radial correction â€” fixes extreme corner errors |
| `pâ‚` | `[âˆ’0.1, 0.1]` | Tangential distortion â€” left/right lens tilt |
| `pâ‚‚` | `[âˆ’0.1, 0.1]` | Tangential distortion â€” up/down lens tilt |

### Why Three Loss Components?

| Loss | Weight | Purpose |
|---|---|---|
| SSIM | 0.5 | Structural similarity â€” rewards geometric accuracy |
| Sobel Edge | 0.3 | Edge alignment â€” prevents zero-coefficient degenerate solution |
| L1 | 0.2 | Pixel accuracy â€” reduces blur |

---

## âš™ï¸ Configuration

| Parameter | Value | Notes |
|---|---|---|
| `CNN_INPUT_SIZE` | 300 Ã— 300 | EfficientNetB3 native input |
| `UNDISTORT_SIZE` | 384 Ã— 384 | Higher res = better geometric detail |
| `BATCH_SIZE` | 48 | Tuned for A100 40GB VRAM |
| `EPOCHS` | 30 | Early stopping with patience = 5 |
| `LEARNING_RATE` | 1e-4 | Stable convergence with Adam |
| `PHASE2_START` | Epoch 8 | Unfreeze top-80 backbone layers |
| `PHASE2_LAYERS` | 80 | Number of B3 layers to unfreeze |
| `LOSS_ALPHA` | 0.5 | SSIM weight |
| `LOSS_BETA` | 0.3 | Sobel edge weight |
| `LOSS_GAMMA` | 0.2 | L1 weight |
| `TRAIN_FRACTION` | 1.0 | Use all 23,118 training pairs |

---

## ğŸ“ˆ Performance (A100 Colab Pro)

| Stage | Time |
|---|---|
| GCS bulk download via `gsutil` | ~2â€“3 min |
| XLA warmup â€” one-time compile | ~25s |
| Phase 1 training â€” epochs 1â€“7, head only | ~8s / epoch |
| Phase 2 training â€” epochs 8â€“30, fine-tune | ~18s / epoch |
| Evaluation + ZIP creation | ~1â€“2 min |
| **Total end-to-end** | **~15â€“20 min** |

---

## ğŸš€ Quick Start

### Prerequisites

- Google Colab Pro with **A100 GPU** runtime
- GCP project with access to the GCS bucket containing training/test data
- Python packages: `tensorflow >= 2.14`, `opencv-python`, `scikit-image`, `google-cloud-storage`

---

### Step-by-Step Instructions

**Step 1 â€” Open the Notebook**

```
https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E
```

**Step 2 â€” Set Runtime to A100**

```
Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ A100 GPU â†’ Save
```

**Step 3 â€” Authenticate with Google Cloud**

```python
from google.colab import auth
auth.authenticate_user()
```

**Step 4 â€” Update the Config Section**

Find the `CONFIG` section and fill in your project details:

```python
GCP_PROJECT_ID      = "your-project-id"
GCS_BUCKET_NAME     = "your-bucket-name"
GCS_TRAIN_FULL_PATH = "bucket-name/path/to/training/images/"
GCS_TEST_FULL_PATH  = "bucket-name/path/to/test/images/"
```

**Step 5 â€” Run All Cells Top to Bottom**

The pipeline runs fully automatically:

| Cell | What it does | Time |
|---|---|---|
| Step 1 | Bulk download via `gsutil -m cp` to local SSD | ~2â€“3 min |
| Step 2 | Build image helpers and DataFrame | ~10s |
| Step 3 | Differentiable Brown-Conrady undistortion layer | ~5s |
| Step 4 | Build EfficientNetB3 CNN model | ~15s |
| Step 5 | Set up loss functions â€” SSIM + Sobel + L1 | ~2s |
| Step 6 | Build `tf.data` parallel pipeline | ~5s |
| Step 7 | Two-phase training loop with checkpointing | ~15 min |
| Step 8 | Qualitative evaluation on sample images | ~30s |
| Step 9 | Batched inference on 1,000 test images | ~15s |
| Step 10 | Create ZIP submission + trigger download | ~1 min |

**Step 6 â€” Download the ZIP**

The file downloads automatically. If it doesn't, run this in a new cell:

```python
from google.colab import files
files.download('/content/lens_correction_cnn_a100.zip')
```

---

## ğŸ“‚ Data Format

### Training Data (GCS)

```
gs://bucket/path/
â”œâ”€â”€ image_001_original.jpg     â† distorted input
â”œâ”€â”€ image_001_generated.jpg    â† ground truth corrected
â”œâ”€â”€ image_002_original.jpg
â”œâ”€â”€ image_002_generated.jpg
â””â”€â”€ ...  (23,118 pairs total)
```

### Test Data (GCS)

```
gs://bucket/path/
â”œâ”€â”€ test_001.jpg
â”œâ”€â”€ test_002.jpg
â””â”€â”€ ...  (1,000 images)
```

---

## ğŸ“¦ Output Files

All outputs saved to `/content/` inside Colab:

```
/content/
â”œâ”€â”€ lens_correction_cnn_a100.zip      â† submission package
â”œâ”€â”€ lens_cnn_model_a100.keras         â† trained model weights
â”œâ”€â”€ training_curves_a100.png          â† loss + SSIM plots per epoch
â”œâ”€â”€ eval_samples_a100.png             â† side-by-side comparisons
â””â”€â”€ output/
    â”œâ”€â”€ outputs/                      â† 1,000 corrected JPEGs
    â”œâ”€â”€ inputs/                       â† 1,000 original copies
    â””â”€â”€ side_by_side/                 â† 1,000 comparison images
```

---

## ğŸ› ï¸ Tech Stack

| Category | Technology |
|---|---|
| **Deep Learning** | TensorFlow 2.14+, Keras 3 |
| **CNN Backbone** | EfficientNetB3 (pretrained ImageNet) |
| **Computer Vision** | OpenCV, Pillow |
| **GPU Optimisation** | bfloat16 mixed precision, XLA JIT compilation |
| **Data Pipeline** | tf.data, native TF JPEG decode (C++) |
| **Cloud Storage** | Google Cloud Storage, gsutil |
| **Infrastructure** | Google Colab Pro (A100 40GB) |
| **AI Development** | Claude AI (Anthropic) |
| **Language** | Python 3.12 |

---

## ğŸ”§ Troubleshooting

**âŒ No GPU detected**
```
Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ A100 GPU â†’ Save
```

**âŒ gsutil auth error (exit code 256)**
```python
# Re-run authentication then retry the download cell
from google.colab import auth
auth.authenticate_user()
```

**âŒ AssertionError: No training pairs found**
```python
# gsutil mirrors the full GCS path â€” files may be nested deeper than expected
import glob
files = glob.glob('/content/train_images/**/*.jpg', recursive=True)
print(f"Found {len(files)} files")
print(files[:3])  # check the actual nested path
```

**âŒ TypeError: ScaleCoefficients bfloat16 mismatch**
> Keras 3 + XLA can bypass standalone cast layers. Fixed in this repo â€” `ScaleCoefficients` owns the `tf.cast` internally.

**âŒ NotImplementedError: Lambda layer shape inference**
> Keras 3 + bfloat16 cannot infer Lambda layer output shapes. Fixed by replacing all Lambda layers with custom `tf.keras.layers.Layer` subclasses.

**âŒ OOM (Out of Memory)**
```python
# Reduce in the CONFIG section
BATCH_SIZE     = 32
UNDISTORT_SIZE = 256
```

---

## ğŸ“š References

- [Brown-Conrady Distortion Model](https://en.wikipedia.org/wiki/Distortion_(optics))
- [EfficientNet: Rethinking Model Scaling](https://arxiv.org/abs/1905.11946)
- [bfloat16 on A100 Tensor Cores](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus)
- [XLA: Optimizing Compiler for TensorFlow](https://www.tensorflow.org/xla)

---

## ğŸ‘¤ Authors

**Deepthi V** Â· **Joshua Jose**

*Developed with [Claude AI](https://claude.ai) (Anthropic) for architecture design, debugging, and iterative optimisation.*

---

## ğŸ“„ License

[Add your license here]
