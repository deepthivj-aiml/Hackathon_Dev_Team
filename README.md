# üî≠ Automatic Lens Distortion Correction ‚Äî A100-Optimised CNN

> A high-performance deep learning pipeline that automatically corrects lens distortion in real estate and property photography using **EfficientNetB3** and differentiable **Brown-Conrady** undistortion, optimised for NVIDIA A100 GPUs on Google Colab Pro.

üìì **[Open in Google Colab](https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E?usp=sharing)**

---

## üì∏ Sample Dataset Images

These are real property photographs from the test dataset. Each image exhibits typical wide-angle lens distortion ‚Äî bowed walls, curved ceilings, warped floor lines ‚Äî that the model learns to detect and correct.

**Property 1 ‚Äî 13 Caledonian St, Aberdare**

| Bathroom | Living / Dining |
|:---:|:---:|
| ![Bathroom with barrel distortion on tiles](assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g7.jpg) | ![Living/dining with curved ceiling lines](assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g2.jpg) |
| *Barrel distortion visible on tile grid lines* | *Wide-angle warp on ceiling and floor* |

**Property 2 ‚Äî 105 Boulder Ridge Trail**

| Master Bedroom | Ensuite Bathroom | Hallway |
|:---:|:---:|:---:|
| ![Master bedroom wide-angle warp](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g8.jpg) | ![Ensuite with marble tile distortion](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g4.jpg) | ![Hallway perspective distortion](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g18.jpg) |
| *Bowed carpet and wall geometry* | *Marble tile grid warping* | *Converging wall lines* |

| Open Plan Living | Walk-in Closet |
|:---:|:---:|
| ![Open plan living floor bow](assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g19.jpg) | ![Walk-in closet shelving distortion](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g7.jpg) |
| *Bowed hardwood floor lines* | *Warped shelf geometry* |

**Property 3 ‚Äî Spiro Collection**

| Bathroom Vanity | Dining Room | Walk-in Closet | Bedroom Closet |
|:---:|:---:|:---:|:---:|
| ![Bathroom vanity curved counter](assets/spiro-c7bc93c5-bdd6-4bfc-19eb-08de68980cd7_g13.jpg) | ![Dining room wall panel warp](assets/spiro-aecdfdbb-7e25-4407-178c-08de6897d3cf_g4.jpg) | ![Walk-in closet shelving](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g7.jpg) | ![Bedroom closet door frame](assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g3.jpg) |
| *Curved granite counter top* | *Wall panel vertical lines bowed* | *Shelving unit warp* | *Door frame barrel effect* |

---

## üéØ Overview

Lens distortion is a systematic optical imperfection where straight lines in the real world appear curved in photographs ‚Äî very common in real estate photography where wide-angle lenses are used to make rooms look larger.

This pipeline works in two stages:

- **Stage 1 ‚Äî Detection:** **EfficientNetB3** examines the distorted photo and predicts 4 distortion coefficients `[k‚ÇÅ, k‚ÇÇ, p‚ÇÅ, p‚ÇÇ]` that describe the lens geometry
- **Stage 2 ‚Äî Correction:** The **Brown-Conrady mathematical model** uses those 4 numbers to compute exactly where every pixel should be, then remaps it using differentiable bilinear sampling

The CNN never directly manipulates pixels ‚Äî it only predicts 4 numbers. All pixel manipulation is deterministic mathematics, which means the correction is geometrically principled and resolution-independent.

---

## ‚ú® Key Features

- **EfficientNetB3 Backbone** ‚Äî 12M parameter pretrained ImageNet model, native 300√ó300 input, detects subtle geometric distortion patterns
- **bfloat16 Mixed Precision** ‚Äî 3√ó throughput vs float32 on A100, no loss scaling needed
- **XLA JIT Compilation** ‚Äî 20‚Äì40% additional speedup via GPU kernel fusion
- **Differentiable Geometry** ‚Äî Brown-Conrady undistortion with backprop-safe bilinear sampling
- **Two-Phase Transfer Learning** ‚Äî frozen backbone ‚Üí progressive fine-tuning of top 80 layers
- **Three-Component Loss** ‚Äî SSIM + Sobel Edge + L1 prevents degenerate zero-coefficient solutions
- **Memory-Safe Pipeline** ‚Äî ~1.3 GB peak RAM via `tf.data` + local SSD streaming
- **Parallel I/O** ‚Äî `gsutil -m cp` bulk download + native TF decode (15‚Äì20√ó faster than Python GCS clients)

---

## üèóÔ∏è Architecture

```
Distorted Image (384√ó384)
        ‚Üì
[CNN Encoder ‚Äî EfficientNetB3]
  ‚Ä¢ Pretrained ImageNet weights (12M parameters)
  ‚Ä¢ Global Average Pooling ‚Üí (1536,)
        ‚Üì
[Regression Head]
  ‚Ä¢ Dense(512, swish) + Dropout(0.3)
  ‚Ä¢ Dense(256, swish) + Dropout(0.2)
  ‚Ä¢ Dense(64,  swish)
  ‚Ä¢ Dense(4, tanh) + ScaleCoefficients layer
        ‚Üì
  [k‚ÇÅ, k‚ÇÇ, p‚ÇÅ, p‚ÇÇ] ‚Äî 4 distortion coefficients
        ‚Üì
[Differentiable Brown-Conrady Undistortion]
  ‚Ä¢ build_distortion_grid()  ‚Äî XLA compiled
  ‚Ä¢ bilinear_sample()        ‚Äî differentiable pixel sampling
        ‚Üì
Corrected Output Image (384√ó384)
        ‚Üì
Loss = 0.5 √ó (1 ‚àí SSIM) + 0.3 √ó Sobel Edge + 0.2 √ó L1
```

### What the 4 Coefficients Mean

| Coefficient | Range | Controls |
|---|---|---|
| `k‚ÇÅ` | `[‚àí1.0, 1.0]` | Primary radial distortion ‚Äî barrel (negative) or pincushion (positive) |
| `k‚ÇÇ` | `[‚àí0.5, 0.5]` | Secondary radial correction ‚Äî fixes extreme corner errors |
| `p‚ÇÅ` | `[‚àí0.1, 0.1]` | Tangential distortion ‚Äî left/right lens tilt |
| `p‚ÇÇ` | `[‚àí0.1, 0.1]` | Tangential distortion ‚Äî up/down lens tilt |

### Why Three Loss Components?

| Loss | Weight | Purpose |
|---|---|---|
| SSIM | 0.5 | Structural similarity ‚Äî rewards geometric accuracy |
| Sobel Edge | 0.3 | Edge alignment ‚Äî prevents zero-coefficient degenerate solution |
| L1 | 0.2 | Pixel accuracy ‚Äî reduces blur |

---

## ‚öôÔ∏è Configuration

| Parameter | Value | Notes |
|---|---|---|
| `CNN_INPUT_SIZE` | 300 √ó 300 | EfficientNetB3 native input |
| `UNDISTORT_SIZE` | 384 √ó 384 | Higher res = better geometric detail |
| `BATCH_SIZE` | 48 | Tuned for A100 40GB VRAM |
| `EPOCHS` | 30 | Early stopping with patience = 5 |
| `LEARNING_RATE` | 1e-4 | Stable convergence with Adam |
| `PHASE2_START` | Epoch 8 | Unfreeze top-80 backbone layers |
| `PHASE2_LAYERS` | 80 | Number of B3 layers to unfreeze |
| `LOSS_ALPHA` | 0.5 | SSIM weight |
| `LOSS_BETA` | 0.3 | Sobel edge weight |
| `LOSS_GAMMA` | 0.2 | L1 weight |
| `TRAIN_FRACTION` | 1.0 | Use all 23,118 training pairs |

---

## üìà Performance (A100 Colab Pro)

| Stage | Time |
|---|---|
| GCS bulk download via `gsutil` | ~2‚Äì3 min |
| XLA warmup ‚Äî one-time compile | ~25s |
| Phase 1 training ‚Äî epochs 1‚Äì7, head only | ~8s / epoch |
| Phase 2 training ‚Äî epochs 8‚Äì30, fine-tune | ~18s / epoch |
| Evaluation + ZIP creation | ~1‚Äì2 min |
| **Total end-to-end** | **~15‚Äì20 min** |

---

## üöÄ Quick Start

### Prerequisites

- Google Colab Pro with **A100 GPU** runtime
- GCP project with access to the GCS bucket containing training/test data
- Python packages: `tensorflow >= 2.14`, `opencv-python`, `scikit-image`, `google-cloud-storage`

---

### Step-by-Step Instructions

**Step 1 ‚Äî Open the Notebook**

```
https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E
```

**Step 2 ‚Äî Set Runtime to A100**

```
Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí A100 GPU ‚Üí Save
```

**Step 3 ‚Äî Authenticate with Google Cloud**

```python
from google.colab import auth
auth.authenticate_user()
```

**Step 4 ‚Äî Update the Config Section**

Find the `CONFIG` section and fill in your project details:

```python
GCP_PROJECT_ID      = "your-project-id"
GCS_BUCKET_NAME     = "your-bucket-name"
GCS_TRAIN_FULL_PATH = "bucket-name/path/to/training/images/"
GCS_TEST_FULL_PATH  = "bucket-name/path/to/test/images/"
```

**Step 5 ‚Äî Run All Cells Top to Bottom**

The pipeline runs fully automatically:

| Cell | What it does | Time |
|---|---|---|
| Step 1 | Bulk download via `gsutil -m cp` to local SSD | ~2‚Äì3 min |
| Step 2 | Build image helpers and DataFrame | ~10s |
| Step 3 | Differentiable Brown-Conrady undistortion layer | ~5s |
| Step 4 | Build EfficientNetB3 CNN model | ~15s |
| Step 5 | Set up loss functions ‚Äî SSIM + Sobel + L1 | ~2s |
| Step 6 | Build `tf.data` parallel pipeline | ~5s |
| Step 7 | Two-phase training loop with checkpointing | ~15 min |
| Step 8 | Qualitative evaluation on sample images | ~30s |
| Step 9 | Batched inference on 1,000 test images | ~15s |
| Step 10 | Create ZIP submission + trigger download | ~1 min |

**Step 6 ‚Äî Download the ZIP**

The file downloads automatically. If it doesn't, run this in a new cell:

```python
from google.colab import files
files.download('/content/lens_correction_cnn_a100.zip')
```

---

## üìÇ Data Format

### Training Data (GCS)

```
gs://bucket/path/
‚îú‚îÄ‚îÄ image_001_original.jpg     ‚Üê distorted input
‚îú‚îÄ‚îÄ image_001_generated.jpg    ‚Üê ground truth corrected
‚îú‚îÄ‚îÄ image_002_original.jpg
‚îú‚îÄ‚îÄ image_002_generated.jpg
‚îî‚îÄ‚îÄ ...  (23,118 pairs total)
```

### Test Data (GCS)

```
gs://bucket/path/
‚îú‚îÄ‚îÄ test_001.jpg
‚îú‚îÄ‚îÄ test_002.jpg
‚îî‚îÄ‚îÄ ...  (1,000 images)
```

---

## üì¶ Output Files

All outputs saved to `/content/` inside Colab:

```
/content/
‚îú‚îÄ‚îÄ lens_correction_cnn_a100.zip      ‚Üê submission package
‚îú‚îÄ‚îÄ lens_cnn_model_a100.keras         ‚Üê trained model weights
‚îú‚îÄ‚îÄ training_curves_a100.png          ‚Üê loss + SSIM plots per epoch
‚îú‚îÄ‚îÄ eval_samples_a100.png             ‚Üê side-by-side comparisons
‚îî‚îÄ‚îÄ output/
    ‚îú‚îÄ‚îÄ outputs/                      ‚Üê 1,000 corrected JPEGs
    ‚îú‚îÄ‚îÄ inputs/                       ‚Üê 1,000 original copies
    ‚îî‚îÄ‚îÄ side_by_side/                 ‚Üê 1,000 comparison images
```

---

## üõ†Ô∏è Tech Stack

| Category | Technology |
|---|---|
| **Deep Learning** | TensorFlow 2.14+, Keras 3 |
| **CNN Backbone** | EfficientNetB3 (pretrained ImageNet) |
| **Computer Vision** | OpenCV, Pillow |
| **GPU Optimisation** | bfloat16 mixed precision, XLA JIT compilation |
| **Data Pipeline** | tf.data, native TF JPEG decode (C++) |
| **Cloud Storage** | Google Cloud Storage, gsutil |
| **Infrastructure** | Google Colab Pro (A100 40GB) |
| **AI Development** | Claude AI (Anthropic) |
| **Language** | Python 3.12 |

---

## üîß Troubleshooting

**‚ùå No GPU detected**
```
Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí A100 GPU ‚Üí Save
```

**‚ùå gsutil auth error (exit code 256)**
```python
# Re-run authentication then retry the download cell
from google.colab import auth
auth.authenticate_user()
```

**‚ùå AssertionError: No training pairs found**
```python
# gsutil mirrors the full GCS path ‚Äî files may be nested deeper than expected
import glob
files = glob.glob('/content/train_images/**/*.jpg', recursive=True)
print(f"Found {len(files)} files")
print(files[:3])  # check the actual nested path
```

**‚ùå TypeError: ScaleCoefficients bfloat16 mismatch**
> Keras 3 + XLA can bypass standalone cast layers. Fixed in this repo ‚Äî `ScaleCoefficients` owns the `tf.cast` internally.

**‚ùå NotImplementedError: Lambda layer shape inference**
> Keras 3 + bfloat16 cannot infer Lambda layer output shapes. Fixed by replacing all Lambda layers with custom `tf.keras.layers.Layer` subclasses.

**‚ùå OOM (Out of Memory)**
```python
# Reduce in the CONFIG section
BATCH_SIZE     = 32
UNDISTORT_SIZE = 256
```

---

## üìö References

- [Brown-Conrady Distortion Model](https://en.wikipedia.org/wiki/Distortion_(optics))
- [EfficientNet: Rethinking Model Scaling](https://arxiv.org/abs/1905.11946)
- [bfloat16 on A100 Tensor Cores](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus)
- [XLA: Optimizing Compiler for TensorFlow](https://www.tensorflow.org/xla)

---

## üë§ Authors

**Deepthi V** ¬∑ **Joshua Jose**

*Developed with [Claude AI](https://claude.ai) (Anthropic) for architecture design, debugging, and iterative optimisation.*

---
