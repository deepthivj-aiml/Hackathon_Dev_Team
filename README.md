# ğŸ”­ Automatic Lens Distortion Correction â€” A100-Optimised CNN

> A high-performance deep learning pipeline that automatically corrects lens distortion in real estate and property photography using **EfficientNetB3** and differentiable **Brown-Conrady** undistortion, optimised for NVIDIA A100 GPUs on Google Colab Pro.

ğŸ““ **[Open in Google Colab](https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E?usp=sharing)**

---

## ğŸ“¸ Sample Input Images

These are real property photographs from the dataset â€” each exhibiting typical wide-angle lens distortion (barrel distortion, curved walls, bowed floors) that the model learns to correct.

<table>
  <tr>
    <td align="center"><img src="assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g7.jpg" width="300"/><br/><sub>Bathroom â€” barrel distortion on tiles</sub></td>
    <td align="center"><img src="assets/tmurphyp-13-caledonian-st-aberdare-a693395210d678b5_g2.jpg" width="300"/><br/><sub>Living/Dining â€” curved ceiling lines</sub></td>
    <td align="center"><img src="assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g8.jpg" width="300"/><br/><sub>Master Bedroom â€” wide-angle warp</sub></td>
  </tr>
  <tr>
    <td align="center"><img src="assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g4.jpg" width="300"/><br/><sub>Ensuite â€” marble tile distortion</sub></td>
    <td align="center"><img src="assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g19.jpg" width="300"/><br/><sub>Open Plan Living â€” floor bow</sub></td>
    <td align="center"><img src="assets/tanaatx-105-boulder-rdg-trl-b35a0fd3544eaca8_g18.jpg" width="300"/><br/><sub>Hallway â€” perspective distortion</sub></td>
  </tr>
  <tr>
    <td align="center"><img src="assets/spiro-c7bc93c5-bdd6-4bfc-19eb-08de68980cd7_g13.jpg" width="300"/><br/><sub>Bathroom Vanity â€” curved counter</sub></td>
    <td align="center"><img src="assets/spiro-aecdfdbb-7e25-4407-178c-08de6897d3cf_g4.jpg" width="300"/><br/><sub>Dining Room â€” wall panel warp</sub></td>
    <td align="center"><img src="assets/spiro-779dc042-017d-4ce7-56d0-08de64b72b1c_g7.jpg" width="300"/><br/><sub>Walk-in Closet â€” shelving distortion</sub></td>
  </tr>
</table>

---

## ğŸ¯ Overview

Lens distortion is a systematic optical imperfection where straight lines in the real world appear curved in photographs. This is particularly common in real estate photography where wide-angle lenses are used to make rooms appear larger.

This pipeline:
1. Trains a CNN to **predict distortion coefficients** [kâ‚, kâ‚‚, pâ‚, pâ‚‚] directly from a distorted photo
2. Feeds those 4 numbers into the **Brown-Conrady mathematical model** which computes exactly where each pixel should be
3. **Remaps every pixel** back to its geometrically correct position using differentiable bilinear sampling

---

## âœ¨ Key Features

- **EfficientNetB3 Backbone** â€” 12M parameter pretrained ImageNet model, native 300Ã—300 input, superior distortion pattern recognition vs B0
- **bfloat16 Mixed Precision** â€” 3Ã— throughput vs float32 on A100, no loss scaling needed
- **XLA JIT Compilation** â€” 20â€“40% additional speedup via GPU kernel fusion
- **Differentiable Geometry** â€” Brown-Conrady undistortion with backprop-safe bilinear sampling
- **Two-Phase Transfer Learning** â€” frozen backbone â†’ progressive fine-tuning of top 80 layers
- **Three-Component Loss** â€” SSIM + Sobel Edge + L1 prevents degenerate zero-coefficient solutions
- **Memory-Safe Pipeline** â€” ~1.3 GB peak RAM via tf.data + local SSD streaming
- **Parallel I/O** â€” gsutil bulk download + native TF decode (15â€“20Ã— faster than Python GCS clients)

---

## ğŸ—ï¸ Architecture

```
Distorted Image (384Ã—384)
        â†“
[CNN Encoder]
  â€¢ EfficientNetB3 (pretrained ImageNet, 300Ã—300 input)
  â€¢ Global Average Pooling â†’ (1536,)
        â†“
[Regression Head]
  â€¢ Dense(512, swish) + Dropout(0.3)
  â€¢ Dense(256, swish) + Dropout(0.2)
  â€¢ Dense(64,  swish)
  â€¢ Dense(4, tanh) + ScaleCoefficients
        â†“
[kâ‚, kâ‚‚, pâ‚, pâ‚‚] â€” distortion coefficients
        â†“
[Differentiable Brown-Conrady Undistortion]
  â€¢ build_distortion_grid() â€” XLA compiled
  â€¢ bilinear_sample()      â€” differentiable
        â†“
Undistorted Image (384Ã—384)
        â†“
Loss = 0.5Ã—(1âˆ’SSIM) + 0.3Ã—SobelEdge + 0.2Ã—L1
```

### Predicted Coefficients

| Coefficient | Range | Meaning |
|---|---|---|
| kâ‚ | [âˆ’1.0, 1.0] | Primary radial distortion (barrel/pincushion) |
| kâ‚‚ | [âˆ’0.5, 0.5] | Secondary radial correction (extreme corners) |
| pâ‚ | [âˆ’0.1, 0.1] | Tangential distortion â€” x-axis lens tilt |
| pâ‚‚ | [âˆ’0.1, 0.1] | Tangential distortion â€” y-axis lens tilt |

---

## âš™ï¸ Configuration

| Parameter | Value | Notes |
|---|---|---|
| `CNN_INPUT_SIZE` | 300Ã—300 | EfficientNetB3 native input |
| `UNDISTORT_SIZE` | 384Ã—384 | Higher res = better geometric detail |
| `BATCH_SIZE` | 48 | Tuned for A100 80GB VRAM |
| `EPOCHS` | 30 | Early stopping with patience=5 |
| `LEARNING_RATE` | 1e-4 | Stable convergence with Adam |
| `PHASE2_START` | Epoch 8 | Unfreeze top-80 backbone layers |
| `LOSS_ALPHA` | 0.5 | SSIM weight |
| `LOSS_BETA` | 0.3 | Sobel edge weight |
| `LOSS_GAMMA` | 0.2 | L1 weight |
| `TRAIN_FRACTION` | 1.0 | Use full 23,118 training pairs |

---

## ğŸ“ˆ Performance (A100 Colab Pro)

| Stage | Time |
|---|---|
| GCS bulk download (gsutil) | ~2â€“3 min |
| XLA warmup (one-time) | ~25s |
| Training Phase 1 (epochs 1â€“7, head only) | ~8s/epoch |
| Training Phase 2 (epochs 8â€“30, fine-tune) | ~18s/epoch |
| Evaluation + ZIP creation | ~1â€“2 min |
| **Total end-to-end** | **~15â€“20 min** |

---

## ğŸš€ Quick Start

### Prerequisites

- Google Colab Pro with **A100 GPU** runtime
- GCP project with access to the GCS bucket containing training data
- Python packages: `tensorflow >= 2.14`, `opencv-python`, `scikit-image`, `google-cloud-storage`

---

### Step-by-Step Instructions

**Step 1 â€” Open the Notebook**

Click the Colab badge at the top or open the link directly:
```
https://colab.research.google.com/drive/1RO26D6DhnsbDcr367jXr0BHYNNSkFC0E
```

**Step 2 â€” Set Runtime to A100**

```
Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ A100 GPU â†’ Save
```

**Step 3 â€” Authenticate with Google Cloud**

```python
from google.colab import auth
auth.authenticate_user()
```

**Step 4 â€” Update the Config Section**

Find the `CONFIG` section in the notebook and update:
```python
GCP_PROJECT_ID      = "your-project-id"
GCS_BUCKET_NAME     = "your-bucket-name"
GCS_TRAIN_FULL_PATH = "bucket-name/path/to/training/images/"
GCS_TEST_FULL_PATH  = "bucket-name/path/to/test/images/"
```

**Step 5 â€” Run All Cells Top to Bottom**

The pipeline runs fully automatically in this order:

| Step | Description | Time |
|---|---|---|
| Step 1 | Bulk download via `gsutil -m cp` to local SSD | ~2â€“3 min |
| Step 2 | Image helpers and DataFrame construction | ~10s |
| Step 3 | Differentiable Brown-Conrady undistortion layer | ~5s |
| Step 4 | Build EfficientNetB3 CNN model | ~15s |
| Step 5 | Loss functions (SSIM + Sobel + L1) | ~2s |
| Step 6 | tf.data parallel pipeline from local SSD | ~5s |
| Step 7 | Two-phase training loop with checkpointing | ~15 min |
| Step 8 | Qualitative evaluation on 5 sample images | ~30s |
| Step 9 | Batched inference on 1,000 test images | ~15s |
| Step 10 | ZIP submission package + browser download | ~1 min |

**Step 6 â€” Download Your Submission**

The ZIP downloads automatically. If it doesn't:
```python
from google.colab import files
files.download('/content/lens_correction_cnn_a100.zip')
```

---

## ğŸ“‚ Data Format

### Training Data (GCS)
```
gs://bucket/path/
â”œâ”€â”€ image_001_original.jpg    â† distorted input
â”œâ”€â”€ image_001_generated.jpg   â† ground truth corrected
â”œâ”€â”€ image_002_original.jpg
â”œâ”€â”€ image_002_generated.jpg
â””â”€â”€ ...  (23,118 pairs total)
```

### Test Data (GCS)
```
gs://bucket/path/
â”œâ”€â”€ test_001.jpg
â”œâ”€â”€ test_002.jpg
â””â”€â”€ ...  (1,000 images)
```

---

## ğŸ“¦ Output Files

All outputs saved to `/content/` in Colab:

```
/content/
â”œâ”€â”€ lens_correction_cnn_a100.zip     â† submission package
â”œâ”€â”€ lens_cnn_model_a100.keras        â† trained model weights
â”œâ”€â”€ training_curves_a100.png         â† loss + SSIM plots
â”œâ”€â”€ eval_samples_a100.png            â† side-by-side comparisons
â””â”€â”€ output/
    â”œâ”€â”€ outputs/                     â† 1,000 corrected JPEGs
    â”œâ”€â”€ inputs/                      â† 1,000 original copies
    â””â”€â”€ side_by_side/                â† 1,000 comparison images
```

---

## ğŸ› ï¸ Tech Stack

| Category | Technology |
|---|---|
| **Deep Learning** | TensorFlow 2.14+, Keras 3 |
| **CNN Backbone** | EfficientNetB3 (pretrained ImageNet) |
| **Computer Vision** | OpenCV, Pillow |
| **GPU Optimisation** | bfloat16 mixed precision, XLA JIT compilation |
| **Data Pipeline** | tf.data, native TF JPEG decode |
| **Cloud Storage** | Google Cloud Storage, gsutil |
| **Infrastructure** | Google Colab Pro (A100 80GB) |
| **AI Development** | Claude AI (Anthropic) |
| **Language** | Python 3.12 |

---

## ğŸ”§ Troubleshooting

**âŒ No GPU detected**
```
Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ A100 GPU â†’ Save
```

**âŒ gsutil auth error**
```python
# Re-run authentication, then retry the download cell
from google.colab import auth
auth.authenticate_user()
```

**âŒ AssertionError: No training pairs found**
```python
# Check what gsutil actually downloaded â€” files may be nested
import glob
files = glob.glob('/content/train_images/**/*.jpg', recursive=True)
print(f"Found {len(files)} files")
print(files[:3])  # check actual paths
```

**âŒ OOM (Out of Memory)**
```python
# Reduce in CONFIG section
BATCH_SIZE     = 32
UNDISTORT_SIZE = 256
```

**âŒ NotImplementedError: Lambda layer shape**
> Keras 3 + bfloat16 cannot infer Lambda layer output shapes.
> Already fixed in this repo using `CastToFloat32` and `ScaleCoefficients` custom layers.

---

## ğŸ“š How It Works

The pipeline solves two problems with one architecture:

1. **Detection** â€” EfficientNetB3 looks at the visual signature of lens distortion (curved walls, bowed floors, warped door frames) and compresses it into 4 numbers [kâ‚, kâ‚‚, pâ‚, pâ‚‚]

2. **Correction** â€” The Brown-Conrady formula uses those 4 numbers to compute, for every output pixel, exactly where in the distorted input to sample from. Bilinear interpolation fills sub-pixel gaps smoothly.

The key insight is that the CNN never directly manipulates pixels â€” it only predicts 4 numbers. All pixel manipulation is deterministic mathematics, which means the correction is geometrically principled and works at any resolution.

---

## ğŸ“„ References

- [Brown-Conrady Distortion Model](https://en.wikipedia.org/wiki/Distortion_(optics))
- [EfficientNet: Rethinking Model Scaling](https://arxiv.org/abs/1905.11946)
- [bfloat16 on A100 Tensor Cores](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus)
- [XLA: Optimizing Compiler for TensorFlow](https://www.tensorflow.org/xla)

---

## ğŸ‘¤ Authors

**Deepthi V** Â· **Joshua Jose**

*Developed with [Claude AI](https://claude.ai) (Anthropic) for architecture design, debugging, and iterative optimisation.*

---

## ğŸ“„ License

[Add your license here]
